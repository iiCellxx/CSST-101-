{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# TOPICS\n",
        "-"
      ],
      "metadata": {
        "id": "MzCYfV2kFZZP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Install dependencies and import libraries"
      ],
      "metadata": {
        "id": "huRL64Kv-9Lr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "HTpS8FF01Nf8",
        "outputId": "5c392810-3b4a-4fa8-bd0b-8ed6681b8078"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.25.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.68.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.1)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.5.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.12.14)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# Install dependencies\n",
        "!pip install tensorflow\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import LSTM, Dense, Embedding\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, Callback\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Download punkt tokenizer for text cleaning\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Load the dataset and clean the data"
      ],
      "metadata": {
        "id": "c2lkMLLf-_x8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "df = pd.read_csv('/content/ROTC_DATASET.csv')\n",
        "\n",
        "# Data Cleaning function\n",
        "def clean_text(text):\n",
        "    text = text.lower()  # Convert to lowercase\n",
        "    text = nltk.word_tokenize(text)  # Tokenize words\n",
        "    text = [word for word in text if word.isalnum()]  # Remove non-alphanumeric tokens\n",
        "    return ' '.join(text)\n",
        "\n",
        "# Combine 'Pattern' and 'Attribute And Correlation' for input\n",
        "df['Pattern'] = df['Pattern']\n",
        "\n",
        "# Clean the 'Pattern' and 'Response' columns\n",
        "df['Pattern'] = df['Pattern'].apply(clean_text)\n",
        "df['Response'] = df['Response'].apply(clean_text)\n",
        "df['Attribute'] = df['Attribute'].apply(clean_text)\n",
        "df['Correlation'] = df['Correlation'].apply(clean_text)\n",
        "\n",
        "# Remove fully duplicate rows\n",
        "df = df.drop_duplicates()\n",
        "\n",
        "# Handle duplicates in the 'Pattern' column by keeping the first occurrence\n",
        "df = df.drop_duplicates(subset='Pattern', keep='first')\n",
        "\n",
        "# Create a new column with formatted responses\n",
        "df['Formatted_Response'] = df['Response'] + \" | Attributes - \" + df['Attribute'] + \" | Correlation - \" + df['Correlation']\n",
        "\n",
        "# Save the cleaned dataset to a new file\n",
        "df.to_csv('/content/ROTC_CLEANED_DATASET.csv', index=False)\n"
      ],
      "metadata": {
        "id": "cKkHQXQu2-eb"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3: Tokenize and pad the input data"
      ],
      "metadata": {
        "id": "x6pTNPbj_GCZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize the patterns\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(df['Pattern'])\n",
        "X = tokenizer.texts_to_sequences(df['Pattern'])\n",
        "\n",
        "# Padding the sequences to ensure uniform input length\n",
        "X_pad = pad_sequences(X, padding='post')\n",
        "\n",
        "# Encode the responses as integers\n",
        "y = np.array([i for i in range(len(df['Formatted_Response']))])\n",
        "\n",
        "# Show tokenized input and padded sequences\n",
        "X_pad[:5], y[:5]\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-WOMgxb3Jjf",
        "outputId": "c22a7a23-568e-4957-960a-15665fdcaf37"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[  1,  11,   2, 152,   6,  10, 246,   7, 102,   0,   0,   0,   0,\n",
              "           0,   0,   0],\n",
              "        [  1,   3,   2,  57,   6,   7, 117,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0],\n",
              "        [  1,  11,   2, 424, 129,   4,   2,   7,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0],\n",
              "        [ 19,  11, 129,  30,   4,   2,   7,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0],\n",
              "        [  1,   3,   7,  22,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0]], dtype=int32),\n",
              " array([0, 1, 2, 3, 4]))"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4: Split the data into training and validation sets"
      ],
      "metadata": {
        "id": "TFgBOIEf_NYb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train-Test Split\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_pad, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "796rHlhY3das"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 5: Build the LSTM model"
      ],
      "metadata": {
        "id": "eXGlMTdK_TMR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if a checkpoint exists and load the model if so\n",
        "checkpoint_path = '/content/ROTC_chatbot_model_checkpoint.keras'\n",
        "if os.path.exists(checkpoint_path):\n",
        "    print(\"Checkpoint found! Loading the model...\")\n",
        "    model = load_model(checkpoint_path)  # Load the model from checkpoint\n",
        "else:\n",
        "    print(\"No checkpoint found. Creating a new model.\")\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=32, input_length=X_pad.shape[1]))\n",
        "    model.add(LSTM(64, return_sequences=False))\n",
        "    model.add(Dense(32, activation='relu'))\n",
        "    model.add(Dense(len(df['Formatted_Response']), activation='softmax'))\n",
        "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Compile the model\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "OTvTdIP73f9O",
        "outputId": "f0d6d50b-1376-4357-fe94-9fa1a4ae1035"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No checkpoint found. Creating a new model.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)              │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 6: Set up early stopping and model checkpoint callbacks"
      ],
      "metadata": {
        "id": "mZXifSHN_gVa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Callbacks for early stopping and checkpoints\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    checkpoint_path, save_best_only=True, monitor='loss', verbose=1\n",
        ")\n",
        "\n",
        "# Custom callback to stop training when accuracy reaches 0.95\n",
        "class AccuracyThresholdCallback(Callback):\n",
        "    def __init__(self, accuracy_threshold=0.98):\n",
        "        super(AccuracyThresholdCallback, self).__init__()\n",
        "        self.accuracy_threshold = accuracy_threshold\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        accuracy = logs.get('accuracy')\n",
        "        if accuracy is not None and accuracy >= self.accuracy_threshold:\n",
        "            print(f\"\\nEpoch {epoch + 1}: Accuracy has reached {self.accuracy_threshold}, stopping training.\")\n",
        "            self.model.stop_training = True\n",
        "\n",
        "# Initialize the callback\n",
        "accuracy_threshold_callback = AccuracyThresholdCallback(accuracy_threshold=0.98)\n",
        "\n"
      ],
      "metadata": {
        "id": "WmwMzR0t_ffy"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 7: Train the model"
      ],
      "metadata": {
        "id": "u64GKaxr_luY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=100, batch_size=32, verbose=1,\n",
        "    callbacks=[checkpoint_callback, accuracy_threshold_callback]\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2YBy5BS6_mO3",
        "outputId": "5a5caa4d-0b23-49f9-910f-1712adc837ba"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m44/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9318 - loss: 0.3412\n",
            "Epoch 1: loss did not improve from 0.39280\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.9301 - loss: 0.3439 - val_accuracy: 0.0000e+00 - val_loss: 61.7286\n",
            "Epoch 2/100\n",
            "\u001b[1m42/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8981 - loss: 0.3725\n",
            "Epoch 2: loss did not improve from 0.39280\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8947 - loss: 0.3794 - val_accuracy: 0.0000e+00 - val_loss: 61.9257\n",
            "Epoch 3/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8725 - loss: 0.4432\n",
            "Epoch 3: loss did not improve from 0.39280\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8718 - loss: 0.4445 - val_accuracy: 0.0000e+00 - val_loss: 61.8383\n",
            "Epoch 4/100\n",
            "\u001b[1m44/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8960 - loss: 0.3733\n",
            "Epoch 4: loss did not improve from 0.39280\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8943 - loss: 0.3774 - val_accuracy: 0.0000e+00 - val_loss: 61.9371\n",
            "Epoch 5/100\n",
            "\u001b[1m41/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9111 - loss: 0.3678\n",
            "Epoch 5: loss did not improve from 0.39280\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9061 - loss: 0.3776 - val_accuracy: 0.0000e+00 - val_loss: 62.1146\n",
            "Epoch 6/100\n",
            "\u001b[1m43/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8784 - loss: 0.4437\n",
            "Epoch 6: loss did not improve from 0.39280\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8762 - loss: 0.4482 - val_accuracy: 0.0000e+00 - val_loss: 62.2046\n",
            "Epoch 7/100\n",
            "\u001b[1m41/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8323 - loss: 0.5470\n",
            "Epoch 7: loss did not improve from 0.39280\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8256 - loss: 0.5624 - val_accuracy: 0.0000e+00 - val_loss: 62.6107\n",
            "Epoch 8/100\n",
            "\u001b[1m44/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6800 - loss: 0.9096\n",
            "Epoch 8: loss did not improve from 0.39280\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6771 - loss: 0.9164 - val_accuracy: 0.0000e+00 - val_loss: 61.7731\n",
            "Epoch 9/100\n",
            "\u001b[1m42/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6529 - loss: 1.0683\n",
            "Epoch 9: loss did not improve from 0.39280\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.6453 - loss: 1.0889 - val_accuracy: 0.0000e+00 - val_loss: 61.4925\n",
            "Epoch 10/100\n",
            "\u001b[1m42/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6661 - loss: 1.0611\n",
            "Epoch 10: loss did not improve from 0.39280\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6599 - loss: 1.0761 - val_accuracy: 0.0000e+00 - val_loss: 61.4464\n",
            "Epoch 11/100\n",
            "\u001b[1m44/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7082 - loss: 0.8545\n",
            "Epoch 11: loss did not improve from 0.39280\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7052 - loss: 0.8610 - val_accuracy: 0.0000e+00 - val_loss: 61.1543\n",
            "Epoch 12/100\n",
            "\u001b[1m44/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7555 - loss: 0.7422\n",
            "Epoch 12: loss did not improve from 0.39280\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.7528 - loss: 0.7481 - val_accuracy: 0.0000e+00 - val_loss: 61.2544\n",
            "Epoch 13/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7814 - loss: 0.6340\n",
            "Epoch 13: loss did not improve from 0.39280\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.7806 - loss: 0.6357 - val_accuracy: 0.0000e+00 - val_loss: 60.8624\n",
            "Epoch 14/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8529 - loss: 0.4670\n",
            "Epoch 14: loss did not improve from 0.39280\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8522 - loss: 0.4691 - val_accuracy: 0.0000e+00 - val_loss: 60.2372\n",
            "Epoch 15/100\n",
            "\u001b[1m44/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9069 - loss: 0.3904\n",
            "Epoch 15: loss did not improve from 0.39280\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9054 - loss: 0.3932 - val_accuracy: 0.0000e+00 - val_loss: 60.6058\n",
            "Epoch 16/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9158 - loss: 0.3818\n",
            "Epoch 16: loss did not improve from 0.39280\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9152 - loss: 0.3828 - val_accuracy: 0.0000e+00 - val_loss: 60.3225\n",
            "Epoch 17/100\n",
            "\u001b[1m44/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9310 - loss: 0.3326\n",
            "Epoch 17: loss improved from 0.39280 to 0.37365, saving model to /content/ROTC_chatbot_model_checkpoint.keras\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9298 - loss: 0.3344 - val_accuracy: 0.0000e+00 - val_loss: 60.5756\n",
            "Epoch 18/100\n",
            "\u001b[1m42/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9479 - loss: 0.2962\n",
            "Epoch 18: loss improved from 0.37365 to 0.33562, saving model to /content/ROTC_chatbot_model_checkpoint.keras\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9457 - loss: 0.2996 - val_accuracy: 0.0000e+00 - val_loss: 60.4552\n",
            "Epoch 19/100\n",
            "\u001b[1m42/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9594 - loss: 0.2749\n",
            "Epoch 19: loss improved from 0.33562 to 0.31367, saving model to /content/ROTC_chatbot_model_checkpoint.keras\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9569 - loss: 0.2782 - val_accuracy: 0.0000e+00 - val_loss: 60.5642\n",
            "Epoch 20/100\n",
            "\u001b[1m44/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9599 - loss: 0.2623\n",
            "Epoch 20: loss improved from 0.31367 to 0.29911, saving model to /content/ROTC_chatbot_model_checkpoint.keras\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9589 - loss: 0.2639 - val_accuracy: 0.0000e+00 - val_loss: 60.4773\n",
            "Epoch 21/100\n",
            "\u001b[1m43/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9688 - loss: 0.2332\n",
            "Epoch 21: loss improved from 0.29911 to 0.28638, saving model to /content/ROTC_chatbot_model_checkpoint.keras\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9671 - loss: 0.2366 - val_accuracy: 0.0000e+00 - val_loss: 60.4016\n",
            "Epoch 22/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9586 - loss: 0.2567\n",
            "Epoch 22: loss did not improve from 0.28638\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9583 - loss: 0.2574 - val_accuracy: 0.0000e+00 - val_loss: 60.3450\n",
            "Epoch 23/100\n",
            "\u001b[1m44/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9627 - loss: 0.2347\n",
            "Epoch 23: loss improved from 0.28638 to 0.28316, saving model to /content/ROTC_chatbot_model_checkpoint.keras\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9615 - loss: 0.2368 - val_accuracy: 0.0000e+00 - val_loss: 60.3584\n",
            "Epoch 24/100\n",
            "\u001b[1m43/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9715 - loss: 0.2364\n",
            "Epoch 24: loss improved from 0.28316 to 0.27612, saving model to /content/ROTC_chatbot_model_checkpoint.keras\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.9699 - loss: 0.2390 - val_accuracy: 0.0000e+00 - val_loss: 60.6417\n",
            "Epoch 25/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9658 - loss: 0.2496\n",
            "Epoch 25: loss improved from 0.27612 to 0.27416, saving model to /content/ROTC_chatbot_model_checkpoint.keras\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.9654 - loss: 0.2502 - val_accuracy: 0.0000e+00 - val_loss: 60.4846\n",
            "Epoch 26/100\n",
            "\u001b[1m44/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9567 - loss: 0.2426\n",
            "Epoch 26: loss did not improve from 0.27416\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9561 - loss: 0.2441 - val_accuracy: 0.0000e+00 - val_loss: 60.5575\n",
            "Epoch 27/100\n",
            "\u001b[1m42/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9717 - loss: 0.2444\n",
            "Epoch 27: loss improved from 0.27416 to 0.26813, saving model to /content/ROTC_chatbot_model_checkpoint.keras\n",
            "\n",
            "Epoch 27: Accuracy has reached 0.95, stopping training.\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9700 - loss: 0.2464 - val_accuracy: 0.0000e+00 - val_loss: 60.5328\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 8: Save the trained model"
      ],
      "metadata": {
        "id": "3el3KrYx_q9m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the final trained model\n",
        "model.save('/content/ROTC_chatbot_model_final.keras')"
      ],
      "metadata": {
        "id": "coBkYmyq_seg"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 9: Error analysis on misclassified data"
      ],
      "metadata": {
        "id": "weU8Ctjb_-zz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 9: Error analysis on misclassified data\n",
        "\n",
        "# Predict classes for validation data\n",
        "y_pred = np.argmax(model.predict(X_val), axis=1)\n",
        "\n",
        "# Get the indices of the validation data (use range based on the number of rows in X_val)\n",
        "val_indices = range(len(X_val))\n",
        "\n",
        "# Create a DataFrame to compare the true and predicted labels\n",
        "misclassified_data = pd.DataFrame({\n",
        "    'True Label': y_val,\n",
        "    'Predicted Label': y_pred,\n",
        "    'Text': df['Pattern'].iloc[val_indices].values  # Access the corresponding text based on indices\n",
        "})\n",
        "\n",
        "# Find rows where the model's prediction is incorrect\n",
        "misclassified_data = misclassified_data[misclassified_data['True Label'] != misclassified_data['Predicted Label']]\n",
        "\n",
        "# Display some of the misclassified data\n",
        "print(\"Misclassified Data Sample:\")\n",
        "print(misclassified_data.head(10))  # Display the first 10 misclassified examples\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G4RbqBWo__0I",
        "outputId": "9669893f-6d20-4851-998b-da6b47853b2b"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Misclassified Data Sample:\n",
            "   True Label  Predicted Label  \\\n",
            "0        1600              388   \n",
            "1         936             1762   \n",
            "2         483              951   \n",
            "3        1352             1339   \n",
            "4        1252              699   \n",
            "5         544              238   \n",
            "6        1235             1516   \n",
            "7        1521              568   \n",
            "8         631             1698   \n",
            "9        1176             1279   \n",
            "\n",
            "                                                Text  \n",
            "0   what are the qualities of a good military leader  \n",
            "1             what is the purpose of military drills  \n",
            "2           what are the core values in the military  \n",
            "3           why are values important in the military  \n",
            "4                        what is military discipline  \n",
            "5               why is military discipline important  \n",
            "6      why should rotc cadets learn military customs  \n",
            "7             how does leadership impact rotc cadets  \n",
            "8           what are military customs and traditions  \n",
            "9  how often should cadets undergo physical training  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 10: Adjust model weights and retrain"
      ],
      "metadata": {
        "id": "EUZa9kehACYT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 10: Adjustments: Calculate Class Weights and Retrain\n",
        "\n",
        "# Calculate class weights to handle class imbalance\n",
        "unique_classes = np.unique(y_train)\n",
        "class_weights = compute_class_weight('balanced', classes=unique_classes, y=y_train)\n",
        "class_weights_dict = {i: weight for i, weight in enumerate(class_weights)}\n",
        "\n",
        "# Retrain the model with class weights\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=100, batch_size=32, verbose=1,\n",
        "    callbacks=[checkpoint_callback, accuracy_threshold_callback],\n",
        "    class_weight=class_weights_dict  # Apply class weights\n",
        ")\n",
        "\n",
        "# Save the adjusted model\n",
        "model.save('/content/ROTC_chatbot_model_adjusted.keras')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mzzAb7xPAJRH",
        "outputId": "6a2c4959-1191-4380-ef88-dee379b6f403"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m43/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9645 - loss: 0.2479\n",
            "Epoch 1: loss improved from inf to 0.26808, saving model to /content/ROTC_chatbot_model_checkpoint.keras\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.9635 - loss: 0.2492 - val_accuracy: 0.0000e+00 - val_loss: 60.4911\n",
            "Epoch 2/100\n",
            "\u001b[1m43/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9635 - loss: 0.2230\n",
            "Epoch 2: loss did not improve from 0.26808\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9620 - loss: 0.2262 - val_accuracy: 0.0000e+00 - val_loss: 60.6624\n",
            "Epoch 3/100\n",
            "\u001b[1m44/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9700 - loss: 0.2221\n",
            "Epoch 3: loss did not improve from 0.26808\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9690 - loss: 0.2241 - val_accuracy: 0.0000e+00 - val_loss: 60.4248\n",
            "Epoch 4/100\n",
            "\u001b[1m44/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9560 - loss: 0.2365\n",
            "Epoch 4: loss did not improve from 0.26808\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9553 - loss: 0.2382 - val_accuracy: 0.0000e+00 - val_loss: 60.5056\n",
            "Epoch 5/100\n",
            "\u001b[1m44/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9519 - loss: 0.2500\n",
            "Epoch 5: loss did not improve from 0.26808\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9508 - loss: 0.2524 - val_accuracy: 0.0000e+00 - val_loss: 60.8339\n",
            "Epoch 6/100\n",
            "\u001b[1m42/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9382 - loss: 0.2812\n",
            "Epoch 6: loss did not improve from 0.26808\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9361 - loss: 0.2856 - val_accuracy: 0.0000e+00 - val_loss: 60.6858\n",
            "Epoch 7/100\n",
            "\u001b[1m42/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9342 - loss: 0.2975\n",
            "Epoch 7: loss did not improve from 0.26808\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9304 - loss: 0.3042 - val_accuracy: 0.0000e+00 - val_loss: 60.7095\n",
            "Epoch 8/100\n",
            "\u001b[1m41/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9087 - loss: 0.3763\n",
            "Epoch 8: loss did not improve from 0.26808\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9034 - loss: 0.3865 - val_accuracy: 0.0000e+00 - val_loss: 60.7661\n",
            "Epoch 9/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8579 - loss: 0.4838\n",
            "Epoch 9: loss did not improve from 0.26808\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8567 - loss: 0.4863 - val_accuracy: 0.0000e+00 - val_loss: 60.6241\n",
            "Epoch 10/100\n",
            "\u001b[1m44/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7490 - loss: 0.6993\n",
            "Epoch 10: loss did not improve from 0.26808\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7473 - loss: 0.7050 - val_accuracy: 0.0000e+00 - val_loss: 60.0236\n",
            "Epoch 11/100\n",
            "\u001b[1m44/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6556 - loss: 1.0342\n",
            "Epoch 11: loss did not improve from 0.26808\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.6520 - loss: 1.0442 - val_accuracy: 0.0000e+00 - val_loss: 61.2201\n",
            "Epoch 12/100\n",
            "\u001b[1m43/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6049 - loss: 1.3789\n",
            "Epoch 12: loss did not improve from 0.26808\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.5993 - loss: 1.3990 - val_accuracy: 0.0000e+00 - val_loss: 61.1215\n",
            "Epoch 13/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5778 - loss: 1.3766\n",
            "Epoch 13: loss did not improve from 0.26808\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.5769 - loss: 1.3784 - val_accuracy: 0.0000e+00 - val_loss: 60.8799\n",
            "Epoch 14/100\n",
            "\u001b[1m41/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6696 - loss: 1.0613\n",
            "Epoch 14: loss did not improve from 0.26808\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.6665 - loss: 1.0598 - val_accuracy: 0.0000e+00 - val_loss: 61.3938\n",
            "Epoch 15/100\n",
            "\u001b[1m42/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7681 - loss: 0.7135\n",
            "Epoch 15: loss did not improve from 0.26808\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7650 - loss: 0.7177 - val_accuracy: 0.0000e+00 - val_loss: 61.3011\n",
            "Epoch 16/100\n",
            "\u001b[1m44/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8431 - loss: 0.4771\n",
            "Epoch 16: loss did not improve from 0.26808\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8422 - loss: 0.4799 - val_accuracy: 0.0000e+00 - val_loss: 60.7053\n",
            "Epoch 17/100\n",
            "\u001b[1m43/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8966 - loss: 0.3825\n",
            "Epoch 17: loss did not improve from 0.26808\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8954 - loss: 0.3850 - val_accuracy: 0.0000e+00 - val_loss: 60.9194\n",
            "Epoch 18/100\n",
            "\u001b[1m42/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9268 - loss: 0.3188\n",
            "Epoch 18: loss did not improve from 0.26808\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9256 - loss: 0.3207 - val_accuracy: 0.0000e+00 - val_loss: 60.5519\n",
            "Epoch 19/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9597 - loss: 0.2598\n",
            "Epoch 19: loss did not improve from 0.26808\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9592 - loss: 0.2606 - val_accuracy: 0.0000e+00 - val_loss: 60.3065\n",
            "Epoch 20/100\n",
            "\u001b[1m42/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9672 - loss: 0.2034\n",
            "Epoch 20: loss improved from 0.26808 to 0.24303, saving model to /content/ROTC_chatbot_model_checkpoint.keras\n",
            "\n",
            "Epoch 20: Accuracy has reached 0.95, stopping training.\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9665 - loss: 0.2068 - val_accuracy: 0.0000e+00 - val_loss: 60.1982\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 11: Function to predict responses\n"
      ],
      "metadata": {
        "id": "8bnqLmsSAUw7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to predict responses\n",
        "def get_response(text):\n",
        "    cleaned_text = clean_text(text)  # Ensure the text is preprocessed\n",
        "    seq = tokenizer.texts_to_sequences([cleaned_text])\n",
        "    padded = pad_sequences(seq, maxlen=X_pad.shape[1], padding='post')\n",
        "    pred = model.predict(padded)\n",
        "    response_idx = np.argmax(pred)\n",
        "    # Extract formatted response (includes Attribute and Correlation)\n",
        "    formatted_response = df['Formatted_Response'].iloc[response_idx]\n",
        "    # Split into main response, attributes, and correlation\n",
        "    main_response = formatted_response.split(\" | \")[0]  # Main response (before 'Attributes')\n",
        "    attributes = formatted_response.split(\" | \")[1].replace(\"Attributes - \", \"\")  # Extract attributes\n",
        "    correlation = formatted_response.split(\" | \")[2].replace(\"Correlation - \", \"\")  # Extract correlation\n",
        "    return f\"Chatbot: {main_response}\\nAttributes: {attributes}\\nCorrelation: {correlation}\"\n",
        "\n"
      ],
      "metadata": {
        "id": "ws99yBZnAX5W"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 13: Chatbot loop for testing"
      ],
      "metadata": {
        "id": "qEtFb1ZgAaNx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chatbot Loop\n",
        "print(\"HELLO! ASK ME ABOUT ROTC KNOWLEDGE. TYPE 'EXIT' TO END THE CONVERSATION.\")\n",
        "while True:\n",
        "    user_input = input(\"YOU: \")\n",
        "    if user_input.lower() == 'exit':\n",
        "        print(\"GOODBYE!\")\n",
        "        break\n",
        "    response = get_response(user_input)\n",
        "    print(response.upper())  # Convert response to uppercase\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "owoWQNcWAdTL",
        "outputId": "50ba83d2-23b0-4451-f6d8-b340cc9ca483"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HELLO! ASK ME ABOUT ROTC KNOWLEDGE. TYPE 'EXIT' TO END THE CONVERSATION.\n",
            "YOU: how did the philippine army contribute to history\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "CHATBOT: THE PHILIPPINE ARMY PLAYED A CRUCIAL ROLE IN DEFENDING THE NATION\n",
            "ATTRIBUTES: PHILIPPINE ARMY\n",
            "CORRELATION: FOUGHT IN MAJOR WARS AND BATTLES FOR THE COUNTRY S SOVEREIGNTY\n",
            "YOU: what role does the philippine navy play in history\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "CHATBOT: THE NAVY PROTECTS THE COUNTRY WATERS AND MAINTAINS NATIONAL SECURITY\n",
            "ATTRIBUTES: PHILIPPINE NAVY\n",
            "CORRELATION: VITAL FOR MARITIME DEFENSE AND TERRITORIAL INTEGRITY\n",
            "YOU: what is a combat helmet designed for\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "CHATBOT: A COMBAT HELMET PROTECTS THE HEAD FROM SHRAPNEL BULLETS AND BLUNT FORCE IMPACTS\n",
            "ATTRIBUTES: WEAPONS AND EQUIPMENT\n",
            "CORRELATION: HELMETS ARE ESSENTIAL FOR MINIMIZING HEAD INJURIES IN COMBAT SITUATIONS\n",
            "YOU: exit\n",
            "GOODBYE!\n"
          ]
        }
      ]
    }
  ]
}